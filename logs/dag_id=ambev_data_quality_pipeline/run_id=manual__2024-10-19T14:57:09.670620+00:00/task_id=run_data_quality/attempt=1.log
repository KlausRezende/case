[2024-10-19T14:57:10.712+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: ambev_data_quality_pipeline.run_data_quality manual__2024-10-19T14:57:09.670620+00:00 [queued]>
[2024-10-19T14:57:10.720+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: ambev_data_quality_pipeline.run_data_quality manual__2024-10-19T14:57:09.670620+00:00 [queued]>
[2024-10-19T14:57:10.720+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-10-19T14:57:10.720+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2024-10-19T14:57:10.720+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-10-19T14:57:10.729+0000] {taskinstance.py:1300} INFO - Executing <Task(BashOperator): run_data_quality> on 2024-10-19 14:57:09.670620+00:00
[2024-10-19T14:57:10.732+0000] {standard_task_runner.py:55} INFO - Started process 24005 to run task
[2024-10-19T14:57:10.734+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'ambev_data_quality_pipeline', 'run_data_quality', 'manual__2024-10-19T14:57:09.670620+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/dag_dataquality.py', '--cfg-path', '/tmp/tmpmmcf3zi5']
[2024-10-19T14:57:10.735+0000] {standard_task_runner.py:83} INFO - Job 40: Subtask run_data_quality
[2024-10-19T14:57:10.746+0000] {logging_mixin.py:137} WARNING - /usr/local/lib/python3.9/site-packages/***/settings.py:249 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2024-10-19T14:57:10.781+0000] {task_command.py:388} INFO - Running <TaskInstance: ambev_data_quality_pipeline.run_data_quality manual__2024-10-19T14:57:09.670620+00:00 [running]> on host 39b0b1bd9d5a
[2024-10-19T14:57:10.825+0000] {taskinstance.py:1507} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Klaus_Rezende
AIRFLOW_CTX_DAG_ID=ambev_data_quality_pipeline
AIRFLOW_CTX_TASK_ID=run_data_quality
AIRFLOW_CTX_EXECUTION_DATE=2024-10-19T14:57:09.670620+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-10-19T14:57:09.670620+00:00
[2024-10-19T14:57:10.826+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2024-10-19T14:57:10.826+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python3 /opt/***/scripts/data_quality_brewery.py']
[2024-10-19T14:57:10.833+0000] {subprocess.py:86} INFO - Output:
[2024-10-19T14:57:14.245+0000] {subprocess.py:93} INFO - Setting default log level to "WARN".
[2024-10-19T14:57:14.245+0000] {subprocess.py:93} INFO - To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[2024-10-19T14:57:14.372+0000] {subprocess.py:93} INFO - 24/10/19 14:57:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-10-19T14:57:20.001+0000] {subprocess.py:93} INFO - Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|██▌       | 2/8 [00:00<00:00, 103.77it/s]Calculating Metrics:  25%|██▌       | 2/8 [00:00<00:00, 92.74it/s] [Stage 1:>                                                        (0 + 16) / 16][Stage 1:===>                                                     (1 + 15) / 16][Stage 1:=======>                                                 (2 + 14) / 16]                                                                                Calculating Metrics:  50%|█████     | 4/8 [00:01<00:01,  2.16it/s]Calculating Metrics:  50%|█████     | 4/8 [00:01<00:01,  2.16it/s]Calculating Metrics:  50%|█████     | 4/8 [00:01<00:01,  2.16it/s]Traceback (most recent call last):
[2024-10-19T14:57:20.001+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/execution_engine/execution_engine.py", line 548, in _process_direct_and_bundled_metric_computation_configurations
[2024-10-19T14:57:20.002+0000] {subprocess.py:93} INFO -     ] = metric_computation_configuration.metric_fn(  # type: ignore[misc] # F not callable
[2024-10-19T14:57:20.002+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/expectations/metrics/metric_provider.py", line 100, in inner_func
[2024-10-19T14:57:20.002+0000] {subprocess.py:93} INFO -     return metric_fn(*args, **kwargs)
[2024-10-19T14:57:20.002+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/expectations/metrics/map_metric_provider/column_condition_partial.py", line 256, in inner_func
[2024-10-19T14:57:20.003+0000] {subprocess.py:93} INFO -     metric_domain_kwargs = get_dbms_compatible_metric_domain_kwargs(
[2024-10-19T14:57:20.003+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/expectations/metrics/util.py", line 703, in get_dbms_compatible_metric_domain_kwargs
[2024-10-19T14:57:20.003+0000] {subprocess.py:93} INFO -     column_name: str | sqlalchemy.quoted_name = get_dbms_compatible_column_names(
[2024-10-19T14:57:20.003+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/expectations/metrics/util.py", line 777, in get_dbms_compatible_column_names
[2024-10-19T14:57:20.003+0000] {subprocess.py:93} INFO -     _verify_column_names_exist_and_get_normalized_typed_column_names_map(
[2024-10-19T14:57:20.003+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/expectations/metrics/util.py", line 873, in _verify_column_names_exist_and_get_normalized_typed_column_names_map
[2024-10-19T14:57:20.004+0000] {subprocess.py:93} INFO -     raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
[2024-10-19T14:57:20.004+0000] {subprocess.py:93} INFO - great_expectations.exceptions.exceptions.InvalidMetricAccessorDomainKwargsKeyError: Error: The column "brewery_id" in BatchData does not exist.
[2024-10-19T14:57:20.004+0000] {subprocess.py:93} INFO - 
[2024-10-19T14:57:20.004+0000] {subprocess.py:93} INFO - The above exception was the direct cause of the following exception:
[2024-10-19T14:57:20.004+0000] {subprocess.py:93} INFO - 
[2024-10-19T14:57:20.005+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2024-10-19T14:57:20.005+0000] {subprocess.py:93} INFO -   File "/opt/***/scripts/data_quality_brewery.py", line 68, in <module>
[2024-10-19T14:57:20.005+0000] {subprocess.py:93} INFO -     validator = add_expectations(validator)
[2024-10-19T14:57:20.005+0000] {subprocess.py:93} INFO -   File "/opt/***/scripts/data_quality_brewery.py", line 46, in add_expectations
[2024-10-19T14:57:20.005+0000] {subprocess.py:93} INFO -     validator.expect_column_values_to_not_be_null(column=column)
[2024-10-19T14:57:20.006+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/validator/validator.py", line 590, in inst_expectation
[2024-10-19T14:57:20.006+0000] {subprocess.py:93} INFO -     raise err
[2024-10-19T14:57:20.006+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/validator/validator.py", line 553, in inst_expectation
[2024-10-19T14:57:20.006+0000] {subprocess.py:93} INFO -     validation_result = expectation.validate(
[2024-10-19T14:57:20.006+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/expectations/expectation.py", line 1314, in validate
[2024-10-19T14:57:20.007+0000] {subprocess.py:93} INFO -     ] = validator.graph_validate(
[2024-10-19T14:57:20.007+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/validator/validator.py", line 1065, in graph_validate
[2024-10-19T14:57:20.007+0000] {subprocess.py:93} INFO -     raise err
[2024-10-19T14:57:20.007+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/validator/validator.py", line 1044, in graph_validate
[2024-10-19T14:57:20.007+0000] {subprocess.py:93} INFO -     ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
[2024-10-19T14:57:20.007+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/validator/validator.py", line 1200, in _resolve_suite_level_graph_and_process_metric_evaluation_errors
[2024-10-19T14:57:20.008+0000] {subprocess.py:93} INFO -     ) = self._metrics_calculator.resolve_validation_graph(
[2024-10-19T14:57:20.008+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/validator/metrics_calculator.py", line 274, in resolve_validation_graph
[2024-10-19T14:57:20.008+0000] {subprocess.py:93} INFO -     resolved_metrics, aborted_metrics_info = graph.resolve(
[2024-10-19T14:57:20.008+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/validator/validation_graph.py", line 202, in resolve
[2024-10-19T14:57:20.008+0000] {subprocess.py:93} INFO -     aborted_metrics_info: _AbortedMetricsInfoDict = self._resolve(
[2024-10-19T14:57:20.009+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/validator/validation_graph.py", line 302, in _resolve
[2024-10-19T14:57:20.009+0000] {subprocess.py:93} INFO -     raise err
[2024-10-19T14:57:20.009+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/validator/validation_graph.py", line 269, in _resolve
[2024-10-19T14:57:20.009+0000] {subprocess.py:93} INFO -     self._execution_engine.resolve_metrics(
[2024-10-19T14:57:20.009+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/execution_engine/execution_engine.py", line 283, in resolve_metrics
[2024-10-19T14:57:20.009+0000] {subprocess.py:93} INFO -     return self._process_direct_and_bundled_metric_computation_configurations(
[2024-10-19T14:57:20.010+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.9/site-packages/great_expectations/execution_engine/execution_engine.py", line 552, in _process_direct_and_bundled_metric_computation_configurations
[2024-10-19T14:57:20.010+0000] {subprocess.py:93} INFO -     raise gx_exceptions.MetricResolutionError(
[2024-10-19T14:57:20.010+0000] {subprocess.py:93} INFO - great_expectations.exceptions.exceptions.MetricResolutionError: Error: The column "brewery_id" in BatchData does not exist.
[2024-10-19T14:57:20.113+0000] {subprocess.py:93} INFO - Calculating Metrics:  50%|█████     | 4/8 [00:01<00:01,  2.03it/s]
[2024-10-19T14:57:20.785+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2024-10-19T14:57:20.796+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/airflow/operators/bash.py", line 196, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-10-19T14:57:20.798+0000] {taskinstance.py:1318} INFO - Marking task as FAILED. dag_id=ambev_data_quality_pipeline, task_id=run_data_quality, execution_date=20241019T145709, start_date=20241019T145710, end_date=20241019T145720
[2024-10-19T14:57:20.808+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 40 for task run_data_quality (Bash command failed. The command returned a non-zero exit code 1.; 24005)
[2024-10-19T14:57:20.825+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2024-10-19T14:57:20.841+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
